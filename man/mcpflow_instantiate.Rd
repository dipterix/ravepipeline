% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mcp-workflows.R
\name{mcpflow_instantiate}
\alias{mcpflow_instantiate}
\title{Instantiate workflow as a chat}
\usage{
mcpflow_instantiate(
  workflow,
  chat = NULL,
  chat_provider = c("ollama", "openai", "claude", "gemini", "cortex", "azure_openai",
    "bedrock", "databricks", "github", "groq", "perplexity", "snowflake", "vllm"),
  chat_args = list(),
  additional_tools = NULL,
  on_tool_request = NULL,
  on_tool_result = NULL,
  use_job_validator = FALSE,
  validator_strict = FALSE,
  validator_verbose = TRUE,
  state_env = NULL,
  ...
)
}
\arguments{
\item{workflow}{A \code{'ravepipeline_mcp_workflow'} object, or a
path/identifier that can be read via \code{\link{mcpflow_read}}.}

\item{chat}{An existing \code{'ellmer'} chat object to configure. If \code{NULL}
(default), a new chat is created using \code{chat_provider}.}

\item{chat_provider}{Character. The chat model to use when creating a
new chat. One of \code{"ollama"} (default), \code{"openai"},
\code{"claude"}, \code{"gemini"}, \code{"cortex"}, \code{"azure_openai"},
\code{"bedrock"}, \code{"databricks"}, \code{"github"}, \code{"groq"},
\code{"perplexity"}, \code{"snowflake"}, \code{"vllm"}. Only used when
\code{chat} is \code{NULL}.}

\item{chat_args}{A named list of additional arguments passed to the
\code{'ellmer'} constructor (e.g., \code{model}, \code{api_key},
\code{base_url}). Only used when \code{chat} is \code{NULL}.}

\item{additional_tools}{A list or vector of MCP tools in addition to
what workflow implicates, to be added to the chat; can be strings or
a list of MCP tool objects; default is \code{NULL} (default)}

\item{on_tool_request}{Optional callback function for tool request events.
Passed to \code{chat$on_tool_request()}. Receives a "content tool request"
object. Can call \code{\link[ellmer]{tool_reject}} to prevent execution.}

\item{on_tool_result}{Optional callback function for tool result events.
Passed to \code{chat$on_tool_result()}. Receives a "content tool result"
object.}

\item{use_job_validator}{Logical. If \code{TRUE}, automatically validate
jobs by \code{\link{mcpflow_job_validator}}. Default is
\code{FALSE}. Ignored if \code{on_tool_request} or \code{on_tool_result}
are provided.}

\item{validator_strict}{Logical. If \code{TRUE} and \code{use_job_validator}
is \code{TRUE}, the validation tool will reject out-of-order tool calls.
Default is \code{FALSE} (advisory warnings only).}

\item{validator_verbose}{Logical. If \code{TRUE} (default) and
\code{use_job_validator} is \code{TRUE}, print progress messages.}

\item{state_env}{Environment or \code{NULL} (default). Environment in which
the MCP tools share and store data; see \code{\link{mcptool_state_factory}}}

\item{...}{Additional arguments passed to \code{\link{mcptool_instantiate}}
for each tool.}
}
\value{
An \code{'ellmer'} chat object with:
\itemize{
\item System prompt set from workflow content (via \code{\link{convert_workflow_to_markdown}})
\item All referenced MCP tools registered
\item Optional validation callbacks attached
}
}
\description{
Creates a chat object configured with the workflow's
system prompt (derived from workflow content) and all referenced tools
registered. Optionally attaches validation callbacks to track job execution.
}
\details{
The system prompt is generated by \code{\link{convert_workflow_to_markdown}},
which includes:
\itemize{
\item Workflow name and description
\item Tool list
\item Settings (dangerous, requires_approval, estimated_duration)
\item Sections with content
\item Jobs with dependencies, conditions, and step details
\item Examples, warnings, and best practices
}
}
\examples{
# Load workflow and create chat with Ollama
wf <- mcpflow_read("ravepipeline::rave_pipeline_class_guide")

# This example requires connecting to external service providers
\dontrun{
# Ollama (default) might require explicit model
chat <- mcpflow_instantiate(wf, chat_args = list(model = "qwen3:8b"))

# Create chat with OpenAI and custom model
chat <- mcpflow_instantiate(
  wf,
  chat_provider = "openai",
  chat_args = list(model = "gpt-4")
)

# Use existing chat object
existing_chat <- ellmer::chat_claude()
chat <- mcpflow_instantiate(wf, chat = existing_chat)

# Enable job validation (advisory mode)
chat <- mcpflow_instantiate(wf, use_job_validator = TRUE)

# Enable strict job validation
chat <- mcpflow_instantiate(wf, use_job_validator = TRUE,
                            validator_strict = TRUE)

# Use chat
chat$chat("Help me set up a power analysis pipeline")
}

}
