% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mcp-workflows.R
\name{mcpflow_instantiate}
\alias{mcpflow_instantiate}
\title{Instantiate Workflow as ellmer Chat}
\usage{
mcpflow_instantiate(
  workflow,
  chat = NULL,
  chat_provider = c("ollama", "openai", "claude", "gemini", "cortex", "azure_openai",
    "bedrock", "databricks", "github", "groq", "perplexity", "snowflake", "vllm"),
  chat_args = list(),
  on_tool_request = NULL,
  on_tool_result = NULL,
  use_job_validator = FALSE,
  validator_strict = FALSE,
  validator_verbose = TRUE,
  ...
)
}
\arguments{
\item{workflow}{A \code{ravepipeline_mcp_workflow} object, or a path/identifier
that can be read via \code{\link{mcpflow_read}}.}

\item{chat}{An existing \code{ellmer} chat object to configure. If \code{NULL}
(default), a new chat is created using \code{chat_provider}.}

\item{chat_provider}{Character. The chat model to use when creating a new chat.
One of \code{"ollama"} (default), \code{"openai"}, \code{"claude"},
\code{"gemini"}, \code{"cortex"}, \code{"azure_openai"}, \code{"bedrock"},
\code{"databricks"}, \code{"github"}, \code{"groq"}, \code{"perplexity"},
\code{"snowflake"}, \code{"vllm"}. Only used when \code{chat} is \code{NULL}.}

\item{chat_args}{A named list of additional arguments passed to the
\code{ellmer::chat_*} constructor (e.g., \code{model}, \code{api_key},
\code{base_url}). Only used when \code{chat} is \code{NULL}.}

\item{on_tool_request}{Optional callback function for tool request events.
Passed to \code{chat$on_tool_request()}. Receives a \code{ContentToolRequest}
object. Can call \code{ellmer::tool_reject(reason)} to prevent execution.}

\item{on_tool_result}{Optional callback function for tool result events.
Passed to \code{chat$on_tool_result()}. Receives a \code{ContentToolResult}
object.}

\item{use_job_validator}{Logical. If \code{TRUE}, automatically attach a
job validator created by \code{\link{mcpflow_job_validator}}. Default is
\code{FALSE}. Ignored if \code{on_tool_request} or \code{on_tool_result}
are provided.}

\item{validator_strict}{Logical. If \code{TRUE} and \code{use_job_validator}
is \code{TRUE}, the validator will reject out-of-order tool calls. Default
is \code{FALSE} (advisory warnings only).}

\item{validator_verbose}{Logical. If \code{TRUE} (default) and
\code{use_job_validator} is \code{TRUE}, print progress messages.}

\item{...}{Additional arguments passed to \code{\link{mcptool_instantiate}}
for each tool.}
}
\value{
An \code{ellmer} chat object with:
\itemize{
\item System prompt set from workflow content (via \code{convert_workflow_to_markdown})
\item All referenced MCP tools registered
\item Optional validation callbacks attached
}
}
\description{
Creates an \code{ellmer} chat object configured with the workflow's
system prompt (derived from workflow content) and all referenced tools registered.
Optionally attaches validation callbacks to track job execution.
}
\details{
The system prompt is generated by \code{\link{convert_workflow_to_markdown}},
which includes:
\itemize{
\item Workflow name and description
\item Tool list
\item Settings (dangerous, requires_approval, estimated_duration)
\item Sections with content
\item Jobs with dependencies, conditions, and step details
\item Examples, warnings, and best practices
}
}
\examples{
\dontrun{
# Load workflow and create chat with Ollama
wf <- mcpflow_read("ravepipeline::rave_pipeline_class_guide")
chat <- mcpflow_instantiate(wf)

# Create chat with OpenAI and custom model
chat <- mcpflow_instantiate(
  wf,
  chat_provider = "openai",
  chat_args = list(model = "gpt-4")
)

# Use existing chat object
existing_chat <- ellmer::chat_claude()
chat <- mcpflow_instantiate(wf, chat = existing_chat)

# Enable job validation (advisory mode)
chat <- mcpflow_instantiate(wf, use_job_validator = TRUE)

# Enable strict job validation
chat <- mcpflow_instantiate(wf, use_job_validator = TRUE, validator_strict = TRUE)

# Use chat
chat$chat("Help me set up a power analysis pipeline")
}

}
